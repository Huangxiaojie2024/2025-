import streamlit as st
import pandas as pd
import json
from datetime import datetime
from supabase import create_client, Client
import io

st.set_page_config(
    page_title="æ­é˜³å¸‚ä¸´åºŠè¯å­¦åˆ†ä¼š - ç®¡ç†å‘˜åå°",
    page_icon="ğŸ“Š",
    layout="wide"
)

# ==================== Supabaseé…ç½® ====================
try:
    SUPABASE_URL = st.secrets["SUPABASE_URL"]
    SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
    ADMIN_PASSWORD = st.secrets.get("ADMIN_PASSWORD", "admin123")
    supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
except Exception as e:
    st.error("âš ï¸ æ•°æ®åº“é…ç½®é”™è¯¯ï¼Œè¯·è”ç³»ç®¡ç†å‘˜")
    st.stop()

# ==================== èº«ä»½éªŒè¯ ====================
def check_password():
    """éªŒè¯ç®¡ç†å‘˜å¯†ç """
    def password_entered():
        if st.session_state["password"] == ADMIN_PASSWORD:
            st.session_state["password_correct"] = True
            del st.session_state["password"]
        else:
            st.session_state["password_correct"] = False

    if "password_correct" not in st.session_state:
        st.markdown("## ğŸ” ç®¡ç†å‘˜ç™»å½•")
        st.text_input(
            "è¯·è¾“å…¥ç®¡ç†å‘˜å¯†ç ", 
            type="password", 
            on_change=password_entered, 
            key="password"
        )
        return False
    elif not st.session_state["password_correct"]:
        st.markdown("## ğŸ” ç®¡ç†å‘˜ç™»å½•")
        st.text_input(
            "è¯·è¾“å…¥ç®¡ç†å‘˜å¯†ç ", 
            type="password", 
            on_change=password_entered, 
            key="password"
        )
        st.error("âŒ å¯†ç é”™è¯¯")
        return False
    else:
        return True

# ==================== æ•°æ®åº“æ“ä½œå‡½æ•° ====================
def get_all_data(table_name):
    """è·å–æ‰€æœ‰æ•°æ®"""
    try:
        result = supabase.table(table_name).select("*").execute()
        return result.data
    except Exception as e:
        st.error(f"è¯»å–{table_name}æ•°æ®å¤±è´¥: {str(e)}")
        return []

def get_unit_data(table_name, unit_name):
    """è·å–å•ä¸ªå•ä½çš„æ•°æ®"""
    try:
        result = supabase.table(table_name).select("*").eq("unit_name", unit_name).execute()
        return result.data
    except Exception as e:
        st.error(f"è¯»å–æ•°æ®å¤±è´¥: {str(e)}")
        return []

def get_summary_documents(unit_name):
    """è·å–å•ä½çš„æ‰€æœ‰å¹´åº¦æ€»ç»“æ–‡æ¡£"""
    try:
        result = supabase.table("summary_documents").select("*").eq("unit_name", unit_name).order("uploaded_at", desc=True).execute()
        return result.data
    except Exception as e:
        st.error(f"è¯»å–æ–‡æ¡£åˆ—è¡¨å¤±è´¥: {str(e)}")
        return []

# ==================== ä¸»ç¨‹åº ====================
def main():
    # éªŒè¯å¯†ç 
    if not check_password():
        return
    
    st.title("ğŸ“Š æ­é˜³å¸‚ä¸´åºŠè¯å­¦åˆ†ä¼šæ•°æ®ç®¡ç†åå°")
    
    # æ·»åŠ ç™»å‡ºæŒ‰é’®
    if st.sidebar.button("ğŸšª é€€å‡ºç™»å½•"):
        st.session_state["password_correct"] = False
        st.rerun()
    
    st.markdown("---")
    
    # è·å–æ‰€æœ‰å•ä½åˆ—è¡¨
    work_summary_data = get_all_data("work_summary")
    all_units = list(set([item['unit_name'] for item in work_summary_data]))
    
    # å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œå°è¯•ä»å…¶ä»–è¡¨è·å–å•ä½åˆ—è¡¨
    if not all_units:
        for table in ["academic_activities", "popular_activities", "competitions", "awards", "research_projects", "publications", "summary_documents"]:
            data = get_all_data(table)
            if data:
                all_units.extend([item['unit_name'] for item in data])
        all_units = list(set(all_units))
    
    if not all_units:
        st.warning("âš ï¸ æš‚æ— æ•°æ®ï¼Œè¯·ç­‰å¾…å„å•ä½æäº¤")
        return
    
    # ä¾§è¾¹æ é€‰æ‹©
    st.sidebar.header("ğŸ“‹ æ•°æ®ç­›é€‰")
    view_mode = st.sidebar.radio(
        "æŸ¥çœ‹æ¨¡å¼",
        ["ğŸ“ˆ æ¦‚è§ˆç»Ÿè®¡", "ğŸ¥ æŒ‰å•ä½æŸ¥çœ‹", "ğŸ“‘ åˆ†ç±»æ±‡æ€»", "ğŸ“¥ æ•°æ®å¯¼å‡º"]
    )
    
    # ========== æ¦‚è§ˆç»Ÿè®¡ ==========
    if view_mode == "ğŸ“ˆ æ¦‚è§ˆç»Ÿè®¡":
        st.header("ğŸ“ˆ æ•°æ®æ¦‚è§ˆ")
        
        # ç»Ÿè®¡ä¿¡æ¯
        col1, col2, col3, col4 = st.columns(4)
        
        academic_data = get_all_data("academic_activities")
        popular_data = get_all_data("popular_activities")
        comp_data = get_all_data("competitions")
        award_data = get_all_data("awards")
        
        with col1:
            st.metric("æäº¤å•ä½æ•°", len(all_units))
        with col2:
            st.metric("å­¦æœ¯æ´»åŠ¨æ€»æ•°", len(academic_data))
        with col3:
            st.metric("ç§‘æ™®æ´»åŠ¨æ€»æ•°", len(popular_data))
        with col4:
            st.metric("æŠ€èƒ½ç«èµ›æ€»æ•°", len(comp_data))
        
        col1, col2, col3 = st.columns(3)
        
        project_data = get_all_data("research_projects")
        pub_data = get_all_data("publications")
        
        with col1:
            st.metric("è·å¥–æ€»æ•°", len(award_data))
        with col2:
            st.metric("ç§‘ç ”ç«‹é¡¹æ€»æ•°", len(project_data))
        with col3:
            st.metric("è®ºæ–‡å‘è¡¨æ€»æ•°", len(pub_data))
        
        st.markdown("---")
        
        # æäº¤æƒ…å†µè¡¨
        st.subheader("å„å•ä½æäº¤æƒ…å†µ")
        submit_data = []
        
        for unit in all_units:
            # è·å–è¯¥å•ä½çš„å¹´åº¦æ€»ç»“æ–‡æ¡£æ•°é‡
            summary_docs = get_summary_documents(unit)
            summary_count = len(summary_docs)
            
            row = {
                'å•ä½åç§°': unit,
                'å¹´åº¦æ€»ç»“': f'{summary_count}ä¸ªç‰ˆæœ¬' if summary_count > 0 else 'âœ—',
                'å­¦æœ¯æ´»åŠ¨': len([item for item in academic_data if item['unit_name'] == unit]),
                'ç§‘æ™®æ´»åŠ¨': len([item for item in popular_data if item['unit_name'] == unit]),
                'æŠ€èƒ½ç«èµ›': len([item for item in comp_data if item['unit_name'] == unit]),
                'è·å¥–æƒ…å†µ': len([item for item in award_data if item['unit_name'] == unit]),
                'ç§‘ç ”ç«‹é¡¹': len([item for item in project_data if item['unit_name'] == unit]),
                'è®ºæ–‡å‘è¡¨': len([item for item in pub_data if item['unit_name'] == unit])
            }
            
            # è·å–æœ€åæ›´æ–°æ—¶é—´
            unit_summary = [item for item in work_summary_data if item['unit_name'] == unit]
            if unit_summary:
                row['æœ€åæ›´æ–°'] = unit_summary[0].get('updated_at', 'æœªçŸ¥')[:19]
                row['è”ç³»äºº'] = unit_summary[0].get('contact_person', 'æœªå¡«å†™')
                row['è”ç³»ç”µè¯'] = unit_summary[0].get('contact_phone', 'æœªå¡«å†™')
            else:
                row['æœ€åæ›´æ–°'] = 'æœªæäº¤'
                row['è”ç³»äºº'] = 'æœªå¡«å†™'
                row['è”ç³»ç”µè¯'] = 'æœªå¡«å†™'
            
            submit_data.append(row)
        
        df_submit = pd.DataFrame(submit_data)
        st.dataframe(df_submit, use_container_width=True, hide_index=True)
    
    # ========== æŒ‰å•ä½æŸ¥çœ‹ ==========
    elif view_mode == "ğŸ¥ æŒ‰å•ä½æŸ¥çœ‹":
        st.header("ğŸ¥ æŒ‰å•ä½æŸ¥çœ‹æ•°æ®")
        
        selected_unit = st.selectbox("é€‰æ‹©å•ä½", sorted(all_units))
        
        if selected_unit:
            tabs = st.tabs([
                "ğŸ“„ å¹´åº¦æ€»ç»“",
                "ğŸ“ å­¦æœ¯æ´»åŠ¨",
                "ğŸ“¢ ç§‘æ™®æ´»åŠ¨",
                "ğŸ† æŠ€èƒ½ç«èµ›",
                "ğŸ¥‡ è·å¥–æƒ…å†µ",
                "ğŸ”¬ ç§‘ç ”ç«‹é¡¹",
                "ğŸ“š è®ºæ–‡å‘è¡¨"
            ])
            
            # å¹´åº¦æ€»ç»“
            with tabs[0]:
                summary_data = get_unit_data("work_summary", selected_unit)
                if summary_data:
                    info = summary_data[0]
                    st.write(f"**è”ç³»äººï¼š** {info.get('contact_person', 'æœªå¡«å†™')}")
                    st.write(f"**è”ç³»ç”µè¯ï¼š** {info.get('contact_phone', 'æœªå¡«å†™')}")
                    st.write(f"**æœ€åæ›´æ–°ï¼š** {info.get('updated_at', 'æœªçŸ¥')[:19]}")
                    
                    st.markdown("---")
                    
                    # è·å–æ‰€æœ‰ç‰ˆæœ¬çš„æ–‡æ¡£
                    summary_docs = get_summary_documents(selected_unit)
                    
                    if summary_docs:
                        st.success(f"âœ… è¯¥å•ä½å·²ä¸Šä¼  {len(summary_docs)} ä¸ªç‰ˆæœ¬çš„å¹´åº¦æ€»ç»“ä¸è®¡åˆ’")
                        
                        for idx, doc in enumerate(summary_docs, 1):
                            with st.expander(f"ğŸ“„ ç‰ˆæœ¬ {idx} - {doc.get('uploaded_at', 'æœªçŸ¥')[:19]}", expanded=(idx==1)):
                                st.write(f"**ä¸Šä¼ æ—¶é—´ï¼š** {doc.get('uploaded_at', 'æœªçŸ¥')[:19]}")
                                st.write(f"**åŸæ–‡ä»¶åï¼š** {doc.get('original_filename', 'æœªçŸ¥')}")
                                st.markdown(f"**ä¸‹è½½é“¾æ¥ï¼š** [ğŸ“„ ç‚¹å‡»ä¸‹è½½]({doc['document_url']})")
                                
                                if idx == 1:
                                    st.info("â­ å½“å‰æœ€æ–°ç‰ˆæœ¬")
                    else:
                        st.info("è¯¥å•ä½å°šæœªä¸Šä¼ å¹´åº¦æ€»ç»“ä¸è®¡åˆ’")
                else:
                    st.info("è¯¥å•ä½å°šæœªæäº¤å¹´åº¦æ€»ç»“ä¸è®¡åˆ’")
            
            # å­¦æœ¯æ´»åŠ¨
            with tabs[1]:
                academic = get_unit_data("academic_activities", selected_unit)
                if academic:
                    st.success(f"âœ… å…± {len(academic)} æ¡å­¦æœ¯æ´»åŠ¨è®°å½•")
                    for idx, act in enumerate(academic, 1):
                        with st.expander(f"{idx}. {act['activity_name']} ({act['activity_date']})"):
                            st.write(f"**æ´»åŠ¨æ—¥æœŸï¼š** {act['activity_date']}")
                            st.write(f"**æ´»åŠ¨åç§°ï¼š** {act['activity_name']}")
                            st.write(f"**æ´»åŠ¨ç®€ä»‹ï¼š** {act['description']}")
                            
                            image_urls = json.loads(act.get('image_urls', '[]'))
                            if image_urls:
                                st.write(f"**æ´»åŠ¨å›¾ç‰‡ï¼š** {len(image_urls)}å¼ ")
                                cols = st.columns(min(len(image_urls), 3))
                                for img_idx, img_url in enumerate(image_urls):
                                    with cols[img_idx % 3]:
                                        try:
                                            st.image(img_url, use_container_width=True)
                                        except:
                                            st.markdown(f"[ğŸ–¼ï¸ æŸ¥çœ‹å›¾ç‰‡]({img_url})")
                else:
                    st.info("è¯¥å•ä½å°šæœªæäº¤å­¦æœ¯æ´»åŠ¨")
            
            # ç§‘æ™®æ´»åŠ¨
            with tabs[2]:
                popular = get_unit_data("popular_activities", selected_unit)
                if popular:
                    st.success(f"âœ… å…± {len(popular)} æ¡ç§‘æ™®æ´»åŠ¨è®°å½•")
                    for idx, act in enumerate(popular, 1):
                        with st.expander(f"{idx}. {act['activity_name']} ({act['activity_date']})"):
                            st.write(f"**æ´»åŠ¨æ—¥æœŸï¼š** {act['activity_date']}")
                            st.write(f"**æ´»åŠ¨åç§°ï¼š** {act['activity_name']}")
                            st.write(f"**æ´»åŠ¨ç®€ä»‹ï¼š** {act['description']}")
                            
                            image_urls = json.loads(act.get('image_urls', '[]'))
                            if image_urls:
                                st.write(f"**æ´»åŠ¨å›¾ç‰‡ï¼š** {len(image_urls)}å¼ ")
                                cols = st.columns(min(len(image_urls), 3))
                                for img_idx, img_url in enumerate(image_urls):
                                    with cols[img_idx % 3]:
                                        try:
                                            st.image(img_url, use_container_width=True)
                                        except:
                                            st.markdown(f"[ğŸ–¼ï¸ æŸ¥çœ‹å›¾ç‰‡]({img_url})")
                else:
                    st.info("è¯¥å•ä½å°šæœªæäº¤ç§‘æ™®æ´»åŠ¨")
            
            # æŠ€èƒ½ç«èµ›
            with tabs[3]:
                comps = get_unit_data("competitions", selected_unit)
                if comps:
                    st.success(f"âœ… å…± {len(comps)} æ¡æŠ€èƒ½ç«èµ›è®°å½•")
                    for idx, comp in enumerate(comps, 1):
                        with st.expander(f"{idx}. {comp['competition_name']} ({comp['competition_date']})"):
                            st.write(f"**ç«èµ›æ—¥æœŸï¼š** {comp['competition_date']}")
                            st.write(f"**ç«èµ›åç§°ï¼š** {comp['competition_name']}")
                            st.write(f"**ç«èµ›ç®€ä»‹ï¼š** {comp['description']}")
                            
                            image_urls = json.loads(comp.get('image_urls', '[]'))
                            if image_urls:
                                st.write(f"**ç«èµ›å›¾ç‰‡ï¼š** {len(image_urls)}å¼ ")
                                cols = st.columns(min(len(image_urls), 3))
                                for img_idx, img_url in enumerate(image_urls):
                                    with cols[img_idx % 3]:
                                        try:
                                            st.image(img_url, use_container_width=True)
                                        except:
                                            st.markdown(f"[ğŸ–¼ï¸ æŸ¥çœ‹å›¾ç‰‡]({img_url})")
                else:
                    st.info("è¯¥å•ä½å°šæœªæäº¤æŠ€èƒ½ç«èµ›")
            
            # è·å¥–æƒ…å†µ
            with tabs[4]:
                awards = get_unit_data("awards", selected_unit)
                if awards:
                    st.success(f"âœ… å…± {len(awards)} æ¡è·å¥–è®°å½•")
                    for idx, award in enumerate(awards, 1):
                        with st.expander(f"{idx}. {award['award_name']} ({award['award_date']})"):
                            st.write(f"**è·å¥–æ—¥æœŸï¼š** {award['award_date']}")
                            st.write(f"**å¥–é¡¹åç§°ï¼š** {award['award_name']}")
                            st.write(f"**é¢å¥–å•ä½ï¼š** {award.get('award_organization', 'æœªå¡«å†™')}")
                            
                            image_urls = json.loads(award.get('image_urls', '[]'))
                            if image_urls:
                                st.write(f"**è·å¥–å›¾ç‰‡ï¼š** {len(image_urls)}å¼ ")
                                cols = st.columns(min(len(image_urls), 3))
                                for img_idx, img_url in enumerate(image_urls):
                                    with cols[img_idx % 3]:
                                        try:
                                            st.image(img_url, use_container_width=True)
                                        except:
                                            st.markdown(f"[ğŸ–¼ï¸ æŸ¥çœ‹å›¾ç‰‡]({img_url})")
                else:
                    st.info("è¯¥å•ä½å°šæœªæäº¤è·å¥–æƒ…å†µ")
            
            # ç§‘ç ”ç«‹é¡¹
            with tabs[5]:
                projects = get_unit_data("research_projects", selected_unit)
                if projects:
                    st.success(f"âœ… å…± {len(projects)} æ¡ç§‘ç ”ç«‹é¡¹è®°å½•")
                    df_data = []
                    for proj in projects:
                        df_data.append({
                            'é¡¹ç›®è´Ÿè´£äºº': proj['project_leader'],
                            'é¡¹ç›®åç§°': proj['project_name'],
                            'ç«‹é¡¹å•ä½': proj['project_unit'],
                            'åŸºé‡‘åç§°': proj['fund_name'],
                            'ç¼–å·': proj['fund_number'],
                            'èµ„åŠ©é‡‘é¢ï¼ˆä¸‡å…ƒï¼‰': proj['fund_amount'],
                            'ç«‹é¡¹æ—¶é—´': proj['project_date']
                        })
                    df = pd.DataFrame(df_data)
                    st.dataframe(df, use_container_width=True, hide_index=True)
                else:
                    st.info("è¯¥å•ä½å°šæœªæäº¤ç§‘ç ”ç«‹é¡¹")
            
            # è®ºæ–‡å‘è¡¨
            with tabs[6]:
                pubs = get_unit_data("publications", selected_unit)
                if pubs:
                    st.success(f"âœ… å…± {len(pubs)} æ¡è®ºæ–‡å‘è¡¨è®°å½•")
                    df_data = []
                    for pub in pubs:
                        df_data.append({
                            'ç±»å‹': pub['publication_type'],
                            'é¢˜ç›®': pub['title'],
                            'åˆŠç‰©åç§°': pub['journal'],
                            'ä½œè€…': pub['author'],
                            'åˆŠç‰©ç­‰çº§': pub['level'],
                            'å‘è¡¨æ—¶é—´': pub['publication_date']
                        })
                    df = pd.DataFrame(df_data)
                    st.dataframe(df, use_container_width=True, hide_index=True)
                else:
                    st.info("è¯¥å•ä½å°šæœªæäº¤è®ºæ–‡å‘è¡¨")
    
    # ========== åˆ†ç±»æ±‡æ€» ==========
    elif view_mode == "ğŸ“‘ åˆ†ç±»æ±‡æ€»":
        st.header("ğŸ“‘ åˆ†ç±»æ•°æ®æ±‡æ€»")
        
        category = st.selectbox(
            "é€‰æ‹©ç±»åˆ«",
            ["ğŸ“„ å¹´åº¦æ€»ç»“æ–‡æ¡£", "ğŸ”¬ ç§‘ç ”ç«‹é¡¹", "ğŸ“š è®ºæ–‡å‘è¡¨", "ğŸ“ å­¦æœ¯æ´»åŠ¨", "ğŸ“¢ ç§‘æ™®æ´»åŠ¨", "ğŸ† æŠ€èƒ½ç«èµ›", "ğŸ¥‡ è·å¥–æƒ…å†µ"]
        )
        
        if category == "ğŸ“„ å¹´åº¦æ€»ç»“æ–‡æ¡£":
            st.subheader("å„å•ä½å¹´åº¦æ€»ç»“æ–‡æ¡£æ±‡æ€»")
            
            all_docs = get_all_data("summary_documents")
            
            if all_docs:
                # æŒ‰å•ä½åˆ†ç»„æ˜¾ç¤º
                units_with_docs = list(set([doc['unit_name'] for doc in all_docs]))
                
                for unit in sorted(units_with_docs):
                    unit_docs = [doc for doc in all_docs if doc['unit_name'] == unit]
                    
                    with st.expander(f"ğŸ¥ {unit} - {len(unit_docs)}ä¸ªç‰ˆæœ¬", expanded=False):
                        for idx, doc in enumerate(sorted(unit_docs, key=lambda x: x['uploaded_at'], reverse=True), 1):
                            col1, col2 = st.columns([7, 3])
                            
                            with col1:
                                st.write(f"**ç‰ˆæœ¬ {idx}**")
                                st.write(f"ä¸Šä¼ æ—¶é—´ï¼š{doc.get('uploaded_at', 'æœªçŸ¥')[:19]}")
                                st.write(f"åŸæ–‡ä»¶åï¼š{doc.get('original_filename', 'æœªçŸ¥')}")
                            
                            with col2:
                                st.markdown(f"[ğŸ“„ ä¸‹è½½æ–‡æ¡£]({doc['document_url']})")
                                if idx == 1:
                                    st.success("æœ€æ–°ç‰ˆæœ¬")
                            
                            st.markdown("---")
                
                st.info(f"å…± {len(units_with_docs)} ä¸ªå•ä½æäº¤äº†å¹´åº¦æ€»ç»“ï¼Œæ€»è®¡ {len(all_docs)} ä¸ªæ–‡æ¡£ç‰ˆæœ¬")
            else:
                st.info("æš‚æ— å¹´åº¦æ€»ç»“æ–‡æ¡£")
        
        elif category == "ğŸ”¬ ç§‘ç ”ç«‹é¡¹":
            projects = get_all_data("research_projects")
            if projects:
                df_data = []
                for proj in projects:
                    df_data.append({
                        'å•ä½åç§°': proj['unit_name'],
                        'é¡¹ç›®è´Ÿè´£äºº': proj['project_leader'],
                        'é¡¹ç›®åç§°': proj['project_name'],
                        'ç«‹é¡¹å•ä½': proj['project_unit'],
                        'åŸºé‡‘åç§°': proj['fund_name'],
                        'ç¼–å·': proj['fund_number'],
                        'èµ„åŠ©é‡‘é¢ï¼ˆä¸‡å…ƒï¼‰': proj['fund_amount'],
                        'ç«‹é¡¹æ—¶é—´': proj['project_date']
                    })
                df = pd.DataFrame(df_data)
                st.dataframe(df, use_container_width=True, hide_index=True)
                st.info(f"å…± {len(projects)} æ¡è®°å½•")
            else:
                st.info("æš‚æ— æ•°æ®")
        
        elif category == "ğŸ“š è®ºæ–‡å‘è¡¨":
            pubs = get_all_data("publications")
            if pubs:
                df_data = []
                for pub in pubs:
                    df_data.append({
                        'å•ä½åç§°': pub['unit_name'],
                        'ç±»å‹': pub['publication_type'],
                        'é¢˜ç›®': pub['title'],
                        'åˆŠç‰©åç§°': pub['journal'],
                        'ä½œè€…': pub['author'],
                        'åˆŠç‰©ç­‰çº§': pub['level'],
                        'å‘è¡¨æ—¶é—´': pub['publication_date']
                    })
                df = pd.DataFrame(df_data)
                st.dataframe(df, use_container_width=True, hide_index=True)
                st.info(f"å…± {len(pubs)} æ¡è®°å½•")
            else:
                st.info("æš‚æ— æ•°æ®")
        
        elif category in ["ğŸ“ å­¦æœ¯æ´»åŠ¨", "ğŸ“¢ ç§‘æ™®æ´»åŠ¨", "ğŸ† æŠ€èƒ½ç«èµ›", "ğŸ¥‡ è·å¥–æƒ…å†µ"]:
            table_map = {
                "ğŸ“ å­¦æœ¯æ´»åŠ¨": "academic_activities",
                "ğŸ“¢ ç§‘æ™®æ´»åŠ¨": "popular_activities",
                "ğŸ† æŠ€èƒ½ç«èµ›": "competitions",
                "ğŸ¥‡ è·å¥–æƒ…å†µ": "awards"
            }
            
            data = get_all_data(table_map[category])
            if data:
                for idx, item in enumerate(data, 1):
                    unit = item['unit_name']
                    
                    if category == "ğŸ¥‡ è·å¥–æƒ…å†µ":
                        title = f"{idx}. {unit} - {item['award_name']} ({item['award_date']})"
                        with st.expander(title):
                            st.write(f"**è·å¥–æ—¥æœŸï¼š** {item['award_date']}")
                            st.write(f"**å¥–é¡¹åç§°ï¼š** {item['award_name']}")
                            st.write(f"**é¢å¥–å•ä½ï¼š** {item.get('award_organization', 'æœªå¡«å†™')}")
                            
                            image_urls = json.loads(item.get('image_urls', '[]'))
                            if image_urls:
                                st.write(f"**å›¾ç‰‡ï¼š** {len(image_urls)}å¼ ")
                                cols = st.columns(min(len(image_urls), 3))
                                for img_idx, img_url in enumerate(image_urls):
                                    with cols[img_idx % 3]:
                                        try:
                                            st.image(img_url, use_container_width=True)
                                        except:
                                            st.markdown(f"[ğŸ–¼ï¸ æŸ¥çœ‹å›¾ç‰‡]({img_url})")
                    
                    elif category == "ğŸ† æŠ€èƒ½ç«èµ›":
                        title = f"{idx}. {unit} - {item['competition_name']} ({item['competition_date']})"
                        description = item['description']
                        with st.expander(title):
                            st.write(f"**ç«èµ›æ—¥æœŸï¼š** {item['competition_date']}")
                            st.write(f"**ç«èµ›åç§°ï¼š** {item['competition_name']}")
                            st.write(f"**ç«èµ›ç®€ä»‹ï¼š** {description}")
                            
                            image_urls = json.loads(item.get('image_urls', '[]'))
                            if image_urls:
                                st.write(f"**å›¾ç‰‡ï¼š** {len(image_urls)}å¼ ")
                                cols = st.columns(min(len(image_urls), 3))
                                for img_idx, img_url in enumerate(image_urls):
                                    with cols[img_idx % 3]:
                                        try:
                                            st.image(img_url, use_container_width=True)
                                        except:
                                            st.markdown(f"[ğŸ–¼ï¸ æŸ¥çœ‹å›¾ç‰‡]({img_url})")
                    
                    else:
                        title = f"{idx}. {unit} - {item['activity_name']} ({item['activity_date']})"
                        description = item['description']
                        with st.expander(title):
                            st.write(f"**æ´»åŠ¨æ—¥æœŸï¼š** {item['activity_date']}")
                            st.write(f"**æ´»åŠ¨åç§°ï¼š** {item['activity_name']}")
                            st.write(f"**æ´»åŠ¨ç®€ä»‹ï¼š** {description}")
                            
                            image_urls = json.loads(item.get('image_urls', '[]'))
                            if image_urls:
                                st.write(f"**å›¾ç‰‡ï¼š** {len(image_urls)}å¼ ")
                                cols = st.columns(min(len(image_urls), 3))
                                for img_idx, img_url in enumerate(image_urls):
                                    with cols[img_idx % 3]:
                                        try:
                                            st.image(img_url, use_container_width=True)
                                        except:
                                            st.markdown(f"[ğŸ–¼ï¸ æŸ¥çœ‹å›¾ç‰‡]({img_url})")
                
                st.info(f"å…± {len(data)} æ¡è®°å½•")
            else:
                st.info("æš‚æ— æ•°æ®")
    
    # ========== æ•°æ®å¯¼å‡º ==========
    elif view_mode == "ğŸ“¥ æ•°æ®å¯¼å‡º":
        st.header("ğŸ“¥ æ•°æ®å¯¼å‡º")
        
        st.info("ğŸ’¡ å¯¼å‡ºçš„Excelå°†åŒ…å«æ‰€æœ‰æ•°æ®å’Œå›¾ç‰‡é“¾æ¥ï¼ŒåŒ…æ‹¬å¤šç‰ˆæœ¬çš„å¹´åº¦æ€»ç»“æ–‡æ¡£ä¿¡æ¯")
        
        if st.button("ğŸ“Š ç”Ÿæˆå®Œæ•´Excelæ±‡æ€»è¡¨ï¼ˆå«å›¾ç‰‡é“¾æ¥ï¼‰", type="primary"):
            with st.spinner("æ­£åœ¨ç”ŸæˆExcelæ–‡ä»¶..."):
                try:
                    output = io.BytesIO()
                    with pd.ExcelWriter(output, engine='openpyxl') as writer:
                        
                        # å¹´åº¦æ€»ç»“æ–‡æ¡£ï¼ˆæ–°å¢ï¼‰
                        all_summary_docs = get_all_data("summary_documents")
                        if all_summary_docs:
                            df_data = []
                            for doc in all_summary_docs:
                                df_data.append({
                                    'å•ä½åç§°': doc['unit_name'],
                                    'åŸæ–‡ä»¶å': doc.get('original_filename', 'æœªçŸ¥'),
                                    'ä¸Šä¼ æ—¶é—´': doc.get('uploaded_at', 'æœªçŸ¥')[:19],
                                    'æ–‡æ¡£é“¾æ¥': doc['document_url']
                                })
                            pd.DataFrame(df_data).to_excel(writer, sheet_name='å¹´åº¦æ€»ç»“æ–‡æ¡£', index=False)
                        
                        # ç§‘ç ”ç«‹é¡¹
                        projects = get_all_data("research_projects")
                        if projects:
                            df_data = []
                            for proj in projects:
                                df_data.append({
                                    'å•ä½åç§°': proj['unit_name'],
                                    'é¡¹ç›®è´Ÿè´£äºº': proj['project_leader'],
                                    'é¡¹ç›®åç§°': proj['project_name'],
                                    'ç«‹é¡¹å•ä½': proj['project_unit'],
                                    'åŸºé‡‘åç§°': proj['fund_name'],
                                    'ç¼–å·': proj['fund_number'],
                                    'èµ„åŠ©é‡‘é¢ï¼ˆä¸‡å…ƒï¼‰': proj['fund_amount'],
                                    'ç«‹é¡¹æ—¶é—´': proj['project_date']
                                })
                            pd.DataFrame(df_data).to_excel(writer, sheet_name='ç§‘ç ”ç«‹é¡¹', index=False)
                        
                        # è®ºæ–‡å‘è¡¨
                        pubs = get_all_data("publications")
                        if pubs:
                            df_data = []
                            for pub in pubs:
                                df_data.append({
                                    'å•ä½åç§°': pub['unit_name'],
                                    'ç±»å‹': pub['publication_type'],
                                    'é¢˜ç›®': pub['title'],
                                    'åˆŠç‰©åç§°': pub['journal'],
                                    'CNå·/å‡ºç‰ˆç¤¾': pub.get('cn_number', ''),
                                    'ä¸»ç®¡éƒ¨é—¨': pub.get('department', ''),
                                    'å·æœŸ': pub.get('issue', ''),
                                    'é¡µç ': pub.get('pages', ''),
                                    'ä½œè€…': pub['author'],
                                    'åˆŠç‰©ç­‰çº§': pub['level'],
                                    'å‘è¡¨æ—¶é—´': pub['publication_date']
                                })
                            pd.DataFrame(df_data).to_excel(writer, sheet_name='è®ºæ–‡å‘è¡¨', index=False)
                        
                        # å­¦æœ¯æ´»åŠ¨ï¼ˆå¸¦å›¾ç‰‡é“¾æ¥ï¼‰
                        academic = get_all_data("academic_activities")
                        if academic:
                            df_data = []
                            for act in academic:
                                image_urls = json.loads(act.get('image_urls', '[]'))
                                df_data.append({
                                    'å•ä½åç§°': act['unit_name'],
                                    'æ—¥æœŸ': act['activity_date'],
                                    'æ´»åŠ¨åç§°': act['activity_name'],
                                    'æ´»åŠ¨ç®€ä»‹': act['description'],
                                    'å›¾ç‰‡é“¾æ¥': '\n'.join(image_urls) if image_urls else 'æ— '
                                })
                            pd.DataFrame(df_data).to_excel(writer, sheet_name='å­¦æœ¯æ´»åŠ¨', index=False)
                        
                        # ç§‘æ™®æ´»åŠ¨ï¼ˆå¸¦å›¾ç‰‡é“¾æ¥ï¼‰
                        popular = get_all_data("popular_activities")
                        if popular:
                            df_data = []
                            for act in popular:
                                image_urls = json.loads(act.get('image_urls', '[]'))
                                df_data.append({
                                    'å•ä½åç§°': act['unit_name'],
                                    'æ—¥æœŸ': act['activity_date'],
                                    'æ´»åŠ¨åç§°': act['activity_name'],
                                    'æ´»åŠ¨ç®€ä»‹': act['description'],
                                    'å›¾ç‰‡é“¾æ¥': '\n'.join(image_urls) if image_urls else 'æ— '
                                })
                            pd.DataFrame(df_data).to_excel(writer, sheet_name='ç§‘æ™®æ´»åŠ¨', index=False)
                        
                        # æŠ€èƒ½ç«èµ›ï¼ˆå¸¦å›¾ç‰‡é“¾æ¥ï¼‰
                        comps = get_all_data("competitions")
                        if comps:
                            df_data = []
                            for comp in comps:
                                image_urls = json.loads(comp.get('image_urls', '[]'))
                                df_data.append({
                                    'å•ä½åç§°': comp['unit_name'],
                                    'æ—¥æœŸ': comp['competition_date'],
                                    'ç«èµ›åç§°': comp['competition_name'],
                                    'ç«èµ›ç®€ä»‹': comp['description'],
                                    'å›¾ç‰‡é“¾æ¥': '\n'.join(image_urls) if image_urls else 'æ— '
                                })
                            pd.DataFrame(df_data).to_excel(writer, sheet_name='æŠ€èƒ½ç«èµ›', index=False)
                        
                        # è·å¥–æƒ…å†µï¼ˆå¸¦å›¾ç‰‡é“¾æ¥å’Œé¢å¥–å•ä½ï¼‰
                        awards = get_all_data("awards")
                        if awards:
                            df_data = []
                            for award in awards:
                                image_urls = json.loads(award.get('image_urls', '[]'))
                                df_data.append({
                                    'å•ä½åç§°': award['unit_name'],
                                    'æ—¥æœŸ': award['award_date'],
                                    'å¥–é¡¹åç§°': award['award_name'],
                                    'é¢å¥–å•ä½': award.get('award_organization', 'æœªå¡«å†™'),
                                    'å›¾ç‰‡é“¾æ¥': '\n'.join(image_urls) if image_urls else 'æ— '
                                })
                            pd.DataFrame(df_data).to_excel(writer, sheet_name='è·å¥–æƒ…å†µ', index=False)
                        
                        # æäº¤æƒ…å†µç»Ÿè®¡
                        work_summary = get_all_data("work_summary")
                        submit_data = []
                        for unit in all_units:
                            # ç»Ÿè®¡å¹´åº¦æ€»ç»“æ–‡æ¡£ç‰ˆæœ¬æ•°
                            unit_summary_docs = [doc for doc in all_summary_docs if doc['unit_name'] == unit] if all_summary_docs else []
                            summary_count = len(unit_summary_docs)
                            
                            # è·å–è”ç³»ä¿¡æ¯
                            unit_info = [item for item in work_summary if item['unit_name'] == unit]
                            contact_person = unit_info[0].get('contact_person', 'æœªå¡«å†™') if unit_info else 'æœªå¡«å†™'
                            contact_phone = unit_info[0].get('contact_phone', 'æœªå¡«å†™') if unit_info else 'æœªå¡«å†™'
                            
                            submit_data.append({
                                'å•ä½åç§°': unit,
                                'è”ç³»äºº': contact_person,
                                'è”ç³»ç”µè¯': contact_phone,
                                'å¹´åº¦æ€»ç»“ç‰ˆæœ¬æ•°': summary_count,
                                'å­¦æœ¯æ´»åŠ¨': len([item for item in academic if item['unit_name'] == unit]) if academic else 0,
                                'ç§‘æ™®æ´»åŠ¨': len([item for item in popular if item['unit_name'] == unit]) if popular else 0,
                                'æŠ€èƒ½ç«èµ›': len([item for item in comps if item['unit_name'] == unit]) if comps else 0,
                                'è·å¥–æƒ…å†µ': len([item for item in awards if item['unit_name'] == unit]) if awards else 0,
                                'ç§‘ç ”ç«‹é¡¹': len([item for item in projects if item['unit_name'] == unit]) if projects else 0,
                                'è®ºæ–‡å‘è¡¨': len([item for item in pubs if item['unit_name'] == unit]) if pubs else 0
                            })
                        pd.DataFrame(submit_data).to_excel(writer, sheet_name='æäº¤æƒ…å†µç»Ÿè®¡', index=False)
                    
                    output.seek(0)
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è½½Excelæ±‡æ€»è¡¨",
                        data=output,
                        file_name=f"æ­é˜³å¸‚ä¸´åºŠè¯å­¦åˆ†ä¼š_æ•°æ®æ±‡æ€»_{datetime.now().strftime('%Y%m%d')}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
                    st.success("âœ… Excelæ–‡ä»¶ç”ŸæˆæˆåŠŸï¼åŒ…å«å¹´åº¦æ€»ç»“æ–‡æ¡£ã€å›¾ç‰‡é“¾æ¥å’Œé¢å¥–å•ä½ä¿¡æ¯")
                except Exception as e:
                    st.error(f"ç”ŸæˆExcelæ—¶å‡ºé”™ï¼š{str(e)}")

if __name__ == "__main__":
    main()
